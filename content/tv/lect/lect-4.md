---
title: Теорвер Лекция 4
draft: false
created: 2024-10-06T23:58
date: 2024-09-23
tags:
  - voice_convert
---

> [!warning] Материал создан на основе данных озвученых на лекции, обработаны и дополнены с использованием #4o

## Затронутые темы:

- Условная вероятность и её определение.
- Теорема умножения вероятностей.
- Независимость событий.
- Формула полной вероятности.
- Формула Байеса.
- Схема испытаний Бернулли.
- Примеры задач: урна с шарами, тест Монту.

---

## Конспект лекции 4:

### Условная вероятность

Условная вероятность события $A$, при условии, что произошло событие $B$, определяется как:

$$
P(A|B) = \frac{P(A \cap B)}{P(B)}, \quad P(B) > 0
$$

Эта формула показывает, как изменяется вероятность одного события в зависимости от того, что произошло другое событие.

Пример: в задаче с урной, содержащей белые и чёрные шары, мы вычисляем вероятность того, что второй шар будет белым при условии, что первый шар был белым.

### Теорема умножения вероятностей

Из формулы условной вероятности следует теорема умножения вероятностей, которая позволяет найти вероятность одновременного наступления двух событий $A$ и $B$:

$$
P(A \cap B) = P(A|B) \cdot P(B)
$$

### Независимость событий

Два события $A$ и $B$ называются независимыми, если выполнение одного из них не влияет на вероятность другого. Формально это выражается равенством:

$$
P(A \cap B) = P(A) \cdot P(B)
$$

Также независимость можно выразить через условную вероятность:

$$
P(A|B) = P(A)
$$

### Формула полной вероятности

Формула полной вероятности используется для вычисления вероятности события, используя разбиение на несколько возможных сценариев. Пусть $H_1, H_2, \dots, H_n$ — полная группа событий, тогда вероятность события $A$ можно выразить как:

$$
P(A) = \sum_{i=1}^n P(A|H_i) \cdot P(H_i)
$$

### Формула Байеса

Формула Байеса позволяет вычислить вероятность гипотезы, если известен результат наблюдения. Для гипотез $H_1, H_2, \dots, H_n$, вероятность каждой из которых известна, формула Байеса выглядит следующим образом:

$$
P(H_i|A) = \frac{P(A|H_i) \cdot P(H_i)}{\sum_{k=1}^n P(A|H_k) \cdot P(H_k)}
$$

Эта формула полезна для нахождения апостериорной вероятности гипотезы на основе новых данных.

### Схема испытаний Бернулли

Схема испытаний Бернулли представляет собой серию независимых испытаний, каждое из которых имеет два исхода: успех (с вероятностью $p$) и неудача (с вероятностью $q = 1 - p$). Вероятность того, что в $n$ испытаниях произойдёт ровно $k$ успехов, вычисляется по формуле биномиального распределения:

$$
P(X = k) = C_n^k p^k (1 - p)^{n - k}
$$

где $C_n^k$ — биномиальный коэффициент:

$$
C_n^k = \frac{n!}{k! (n - k)!}
$$

### Пример: задача с урной

В урне находятся $A$ белых и $B$ чёрных шаров. Из урны поочерёдно извлекаются два шара. Требуется найти вероятность того, что второй шар будет белым, при условии, что первый шар был белым. В этом примере используется условная вероятность для вычисления искомого результата.

### Пример: тест Монту

Тест на туберкулёз (реакция Монту) даёт положительный результат для больных с вероятностью 0.95. Для здоровых вероятность ложноположительного результата составляет 0.1. Вероятность того, что человек болен, если тест дал положительный результат, можно найти с помощью формулы Байеса. Вычисления показывают, что даже при положительном результате вероятность заболевания может быть невысокой, что связано с низкой распространённостью болезни.
